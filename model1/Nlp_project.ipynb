{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import nltk.corpus as corpus\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "grame_2 = pd.read_fwf(\"data/w2_.txt\",header=None)\n",
    "grame_3 = pd.read_fwf(\"data/w3_.txt\",header=None)\n",
    "grame_4 = pd.read_fwf(\"data/w4_.txt\",header=None)\n",
    "grame_5 = pd.read_fwf(\"data/w5_.txt\",header=None)\n",
    "test_set = pd.read_fwf(\"test/wikipedia.txt\",sep=\": \",header=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(words):\n",
    "    words = words.split(\"\\t\")\n",
    "    return words[0].lower()\n",
    "def word1(words):\n",
    "    words = words.split(\"\\t\")\n",
    "    return words[1]\n",
    "def word2(words):\n",
    "    words = words.split(\"\\t\")\n",
    "    if(len(words)>=3):\n",
    "        return words[2].lower()\n",
    "    else:\n",
    "        return \" \" \n",
    "def word3(words):\n",
    "    words = words.split(\"\\t\")\n",
    "    if(len(words)>=4):\n",
    "        return words[3].lower()\n",
    "    else:\n",
    "        return \" \" \n",
    "\n",
    "def word4(words):\n",
    "    words = words.split(\"\\t\")\n",
    "    if(len(words)>=5):\n",
    "        return words[4].lower()\n",
    "    else:\n",
    "        return \" \" \n",
    "\n",
    "    \n",
    "def word5(words):\n",
    "    words = words.split(\"\\t\")\n",
    "    if(len(words)>=6):\n",
    "        return words[5].lower()\n",
    "    else:\n",
    "        return \" \" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words  = corpus.words.words()\n",
    "def to_lower(word):\n",
    "    return word.lower()\n",
    "all_words = pd.DataFrame(all_words)[0].apply(to_lower)\n",
    "all_words = pd.unique(all_words)\n",
    "# grame_2[0] = grame_2[0].apply(to_lower)\n",
    "# grame_3[0] = grame_3[0].apply(to_lower)\n",
    "# grame_4[0] = grame_4[0].apply(to_lower)\n",
    "# grame_5[0] = grame_5[0].apply(to_lower)\n",
    "\n",
    "\n",
    "grame_2[\"freq\"]  = grame_2[0].apply(freq)\n",
    "grame_2[\"word1\"] = grame_2[0].apply(word1)\n",
    "grame_2[\"word2\"] = grame_2[0].apply(word2)\n",
    "\n",
    "grame_3[\"freq\"]  = grame_3[0].apply(freq)\n",
    "grame_3[\"word1\"] = grame_3[0].apply(word1)\n",
    "grame_3[\"word2\"] = grame_3[0].apply(word2)\n",
    "grame_3[\"word3\"] = grame_3[0].apply(word3)\n",
    "\n",
    "grame_4[\"freq\"]  = grame_4[0].apply(freq)\n",
    "grame_4[\"word1\"] = grame_4[0].apply(word1)\n",
    "grame_4[\"word2\"] = grame_4[0].apply(word2)\n",
    "grame_4[\"word3\"] = grame_4[0].apply(word3)\n",
    "grame_4[\"word4\"] = grame_4[0].apply(word4)\n",
    "\n",
    "grame_5[\"freq\"]  = grame_5[0].apply(freq)\n",
    "grame_5[\"word1\"] = grame_5[0].apply(word1)\n",
    "grame_5[\"word2\"] = grame_5[0].apply(word2)\n",
    "grame_5[\"word3\"] = grame_5[0].apply(word3)\n",
    "grame_5[\"word4\"] = grame_5[0].apply(word4)\n",
    "grame_5[\"word5\"] = grame_5[0].apply(word5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate(paragraph):\n",
    "    words = paragraph.split(\" \")\n",
    "    flag_cond = 1\n",
    "    if(len(words) == 5):\n",
    "        word_candidate = (grame_5[(grame_5['word1'] == words[0]) & (grame_5['word2'] == words[1]) & (grame_5['word3'] == words[2])&(grame_5['word4'] == words[3])])['word5']\n",
    "        if(len(word_candidate) > 0):\n",
    "            flag_cond = 0\n",
    "        else:\n",
    "            words[1:]\n",
    "    if(len(words) == 4 and flag_cond == 1):\n",
    "        word_candidate = (grame_4[(grame_4['word1'] == words[0])&(grame_4['word2'] == words[1])&(grame_4['word3'] == words[2])])['word4']\n",
    "        if(len(word_candidate) > 0):\n",
    "            flag_cond = 0\n",
    "        else:\n",
    "            words[1:]            \n",
    "    if(len(words) == 3 and flag_cond == 1):\n",
    "        word_candidate = (grame_3[(grame_3['word1'] == words[0])&(grame_3['word2'] == words[1])])['word3']\n",
    "        if(len(word_candidate) > 0):\n",
    "            flag_cond = 0\n",
    "        else:\n",
    "            words[1:]\n",
    "    if(len(words) == 2 and flag_cond == 1):\n",
    "        word_candidate = (grame_2[(grame_2['word1'] == words[0])])['word2']\n",
    "        if(len(word_candidate) > 0):\n",
    "            flag_cond = 0\n",
    "        else:\n",
    "            words[1:]\n",
    "    if(flag_cond == 1):\n",
    "        word_candidate = all_words\n",
    "        \n",
    "    word_candidate = pd.DataFrame(word_candidate)\n",
    "    word_candidate.columns = [0]\n",
    "    if(len(word_candidate[word_candidate[0] == words[-1]]) > 0):\n",
    "        return (words[-1],-1)\n",
    "    else:\n",
    "        return (words[-1],get_num_candidate(words[-1],word_candidate,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_candidate(word,candidate,num):\n",
    "    def get_distance(word_candidate):\n",
    "        return nltk.edit_distance(word,word_candidate)\n",
    "#     print(word)\n",
    "    candidate['distance'] = candidate[0].apply(get_distance)\n",
    "    return(candidate.sort_values(by=\"distance\").head(num))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gui_condiate(text):\n",
    "    print (text)\n",
    "    gui_text = {}\n",
    "    words = text.split(' ')\n",
    "    for i in range(0,len(words)):\n",
    "        \n",
    "        if(i < 4):\n",
    "            text = \" \".join(words[0:i+1])\n",
    "        else:\n",
    "            text = \" \".join(words[i-4:i+1])\n",
    "#         print(text)\n",
    "        if(i in gui_text):\n",
    "            if(gui_text[i] != words[i]):\n",
    "                cand = candidate(text)\n",
    "                if(type(cand[-1]) == pd.core.frame.DataFrame):\n",
    "                    gui_text[i] = (cand[0],cand[1][0].values.tolist())\n",
    "                else:\n",
    "                    gui_text[i] = (cand[0],[])\n",
    "        else:\n",
    "            cand = candidate(text)\n",
    "            if(type(cand[-1]) == pd.core.frame.DataFrame):\n",
    "                gui_text[i] = (cand[0],cand[1][0].values.tolist())\n",
    "            else:\n",
    "                gui_text[i] = (cand[0],[])\n",
    "                \n",
    "    return gui_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrong_word(row):\n",
    "    return row.split(':')[0].lower().strip()\n",
    "def target(row):\n",
    "    return row.split(':')[1].lower().strip().split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"wrong_word\"] = test_set[0].apply(wrong_word)\n",
    "test_set[\"target\"] = test_set[0].apply(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gui_condiate(text):\n",
    "    cand = candidate(text)\n",
    "    if(type(cand[-1]) == pd.core.frame.DataFrame):\n",
    "        return get_num_candidate(cand[0],cand[1],3)[0].values.tolist()\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_select(word):\n",
    "    return not(word in all_words)\n",
    "a = test_set[\"wrong_word\"].apply(fun_select)\n",
    "test_set = test_set[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_set['y_hat'] = test_set[\"wrong_word\"].apply(test_gui_condiate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>wrong_word</th>\n",
       "      <th>target</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apennines: Apenines Appenines</td>\n",
       "      <td>apennines</td>\n",
       "      <td>[apenines, appenines]</td>\n",
       "      <td>[apennine, pentine, appendices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athenians: Atheneans</td>\n",
       "      <td>athenians</td>\n",
       "      <td>[atheneans]</td>\n",
       "      <td>[athenian, athenianly, atheris]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernoulli: Bernouilli</td>\n",
       "      <td>bernoulli</td>\n",
       "      <td>[bernouilli]</td>\n",
       "      <td>[bernoullian, beroll, seriously]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cambridge: Cambrige</td>\n",
       "      <td>cambridge</td>\n",
       "      <td>[cambrige]</td>\n",
       "      <td>[abridge, cartridge, labridae]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Caracas: carcas</td>\n",
       "      <td>caracas</td>\n",
       "      <td>[carcas]</td>\n",
       "      <td>[carajas, caracal, carica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Catiline: Cataline</td>\n",
       "      <td>catiline</td>\n",
       "      <td>[cataline]</td>\n",
       "      <td>[capeline, cathinine, catalina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Connecticut: Conneticut</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>[conneticut]</td>\n",
       "      <td>[connectant, connectivity, connective]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cypriot: Cyprian</td>\n",
       "      <td>cypriot</td>\n",
       "      <td>[cyprian]</td>\n",
       "      <td>[cypriote, cyprina, capriote]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ellis: eles</td>\n",
       "      <td>ellis</td>\n",
       "      <td>[eles]</td>\n",
       "      <td>[elvis, bellis, allie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Europeans: Europians</td>\n",
       "      <td>europeans</td>\n",
       "      <td>[europians]</td>\n",
       "      <td>[european, europeanly, europeanism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Franciscans: Fransiscans</td>\n",
       "      <td>franciscans</td>\n",
       "      <td>[fransiscans]</td>\n",
       "      <td>[franciscan, francisca, franciscanism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Galatians: Galations</td>\n",
       "      <td>galatians</td>\n",
       "      <td>[galations]</td>\n",
       "      <td>[galatian, galaxian, palatian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Gandhi: Ghandi</td>\n",
       "      <td>gandhi</td>\n",
       "      <td>[ghandi]</td>\n",
       "      <td>[sandhi, gondi, gander]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Gauguin: gogin</td>\n",
       "      <td>gauguin</td>\n",
       "      <td>[gogin]</td>\n",
       "      <td>[gaduin, gaulin, gauging]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Guatemala: Guatamala</td>\n",
       "      <td>guatemala</td>\n",
       "      <td>[guatamala]</td>\n",
       "      <td>[guatemalan, grateman, guemal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Guinness: Guiness</td>\n",
       "      <td>guinness</td>\n",
       "      <td>[guiness]</td>\n",
       "      <td>[guianese, vainness, twinness]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Israelis: Israelies</td>\n",
       "      <td>israelis</td>\n",
       "      <td>[israelies]</td>\n",
       "      <td>[israeli, israel, ismaelism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Libya: Lybia</td>\n",
       "      <td>libya</td>\n",
       "      <td>[lybia]</td>\n",
       "      <td>[libra, libyan, iba]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mara_Liasson: liason</td>\n",
       "      <td>mara_liasson</td>\n",
       "      <td>[liason]</td>\n",
       "      <td>[cabalassou, baralipton, moralization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Massachusetts: Massachussets Massachussetts</td>\n",
       "      <td>massachusetts</td>\n",
       "      <td>[massachussets, massachussetts]</td>\n",
       "      <td>[massageuse, massacrer, massecuite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Muslim: Mohammedan Muhammadan</td>\n",
       "      <td>muslim</td>\n",
       "      <td>[mohammedan, muhammadan]</td>\n",
       "      <td>[muslin, musci, mulism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Muslims: Mohammedans</td>\n",
       "      <td>muslims</td>\n",
       "      <td>[mohammedans]</td>\n",
       "      <td>[muslin, muselike, tussis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Nazareth: Nazereth</td>\n",
       "      <td>nazareth</td>\n",
       "      <td>[nazereth]</td>\n",
       "      <td>[nazarite, lazaret, nazarene]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>New_Yorker: Newyorker</td>\n",
       "      <td>new_yorker</td>\n",
       "      <td>[newyorker]</td>\n",
       "      <td>[reworked, worker, newmarket]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Nuremberg: Nuremburg</td>\n",
       "      <td>nuremberg</td>\n",
       "      <td>[nuremburg]</td>\n",
       "      <td>[number, november, curber]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Puccini: Pucini</td>\n",
       "      <td>puccini</td>\n",
       "      <td>[pucini]</td>\n",
       "      <td>[puccinia, succinic, uncini]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Rockefeller: Rockerfeller</td>\n",
       "      <td>rockefeller</td>\n",
       "      <td>[rockerfeller]</td>\n",
       "      <td>[rocketeer, coreveller, backfiller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Saturdays: Saterdays</td>\n",
       "      <td>saturdays</td>\n",
       "      <td>[saterdays]</td>\n",
       "      <td>[saturday, saturnal, saturnale]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Valletta: Valetta</td>\n",
       "      <td>valletta</td>\n",
       "      <td>[valetta]</td>\n",
       "      <td>[pallette, vallota, varletto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Zionists: Sionists</td>\n",
       "      <td>zionists</td>\n",
       "      <td>[sionists]</td>\n",
       "      <td>[zionist, zionistic, zionism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>anomalies: anomolies</td>\n",
       "      <td>anomalies</td>\n",
       "      <td>[anomolies]</td>\n",
       "      <td>[animalier, anomalist, anomalous]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>apartments: appartments</td>\n",
       "      <td>apartments</td>\n",
       "      <td>[appartments]</td>\n",
       "      <td>[apartment, apartmental, awardment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>apologies: appologies</td>\n",
       "      <td>apologies</td>\n",
       "      <td>[appologies]</td>\n",
       "      <td>[apologia, apologist, apologize]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>appearances: appearences</td>\n",
       "      <td>appearances</td>\n",
       "      <td>[appearences]</td>\n",
       "      <td>[appearanced, appearance, coappearance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>approaches: approachs</td>\n",
       "      <td>approaches</td>\n",
       "      <td>[approachs]</td>\n",
       "      <td>[approacher, approachless, approach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>archaeologists: archeaologists</td>\n",
       "      <td>archaeologists</td>\n",
       "      <td>[archeaologists]</td>\n",
       "      <td>[archaeologist, archaeological, archaeologic]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>archeologist: archeaologist</td>\n",
       "      <td>archeologist</td>\n",
       "      <td>[archeaologist]</td>\n",
       "      <td>[archaeologist, areologist, araneologist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>archeologists: archeaologists</td>\n",
       "      <td>archeologists</td>\n",
       "      <td>[archeaologists]</td>\n",
       "      <td>[archaeologist, araneologist, arachnologist]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>archeology: archaoelogy archaology</td>\n",
       "      <td>archeology</td>\n",
       "      <td>[archaoelogy, archaology]</td>\n",
       "      <td>[archaeology, archelogy, archology]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>archetypes: archtypes</td>\n",
       "      <td>archetypes</td>\n",
       "      <td>[archtypes]</td>\n",
       "      <td>[archetype, archetypic, archetypal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>architects: archetects</td>\n",
       "      <td>architects</td>\n",
       "      <td>[archetects]</td>\n",
       "      <td>[architect, architecture, architeuthis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>archived: achived</td>\n",
       "      <td>archived</td>\n",
       "      <td>[achived]</td>\n",
       "      <td>[archive, archival, archie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>arrested: erested</td>\n",
       "      <td>arrested</td>\n",
       "      <td>[erested]</td>\n",
       "      <td>[arrestee, arrester, arrased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>aspects: spects</td>\n",
       "      <td>aspects</td>\n",
       "      <td>[spects]</td>\n",
       "      <td>[aspect, specus, specs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>assassinated: assasinated</td>\n",
       "      <td>assassinated</td>\n",
       "      <td>[assasinated]</td>\n",
       "      <td>[assassinate, assassinator, unassassinated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>assassinates: assasinates</td>\n",
       "      <td>assassinates</td>\n",
       "      <td>[assasinates]</td>\n",
       "      <td>[assassinate, assassinator, assassinatress]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>assassinations: assasinations</td>\n",
       "      <td>assassinations</td>\n",
       "      <td>[assasinations]</td>\n",
       "      <td>[assassination, assassinatress, assassinator]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>assassins: assasins</td>\n",
       "      <td>assassins</td>\n",
       "      <td>[assasins]</td>\n",
       "      <td>[assassin, assassinist, assession]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>attained: attaindre</td>\n",
       "      <td>attained</td>\n",
       "      <td>[attaindre]</td>\n",
       "      <td>[attainer, trained, attainder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>attempted: attemted</td>\n",
       "      <td>attempted</td>\n",
       "      <td>[attemted]</td>\n",
       "      <td>[attempter, untempted, adempted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>attempting: attemting</td>\n",
       "      <td>attempting</td>\n",
       "      <td>[attemting]</td>\n",
       "      <td>[tempting, unattempting, untempting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>attempts: attemts</td>\n",
       "      <td>attempts</td>\n",
       "      <td>[attemts]</td>\n",
       "      <td>[attempt, attempter, attemper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>attendants: attendents</td>\n",
       "      <td>attendants</td>\n",
       "      <td>[attendents]</td>\n",
       "      <td>[attendant, attendancy, attendance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>attributes: atributes</td>\n",
       "      <td>attributes</td>\n",
       "      <td>[atributes]</td>\n",
       "      <td>[attribute, attributer, attributal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>averaged: averageed</td>\n",
       "      <td>averaged</td>\n",
       "      <td>[averageed]</td>\n",
       "      <td>[averager, average, avenage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>bandwidth: bandwith</td>\n",
       "      <td>bandwidth</td>\n",
       "      <td>[bandwith]</td>\n",
       "      <td>[bindwith, bandaite, banditti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>became: becamae</td>\n",
       "      <td>became</td>\n",
       "      <td>[becamae]</td>\n",
       "      <td>[befame, become, bename]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>beginners: begginers</td>\n",
       "      <td>beginners</td>\n",
       "      <td>[begginers]</td>\n",
       "      <td>[beginner, beginger, ginners]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>beginnings: begginings</td>\n",
       "      <td>beginnings</td>\n",
       "      <td>[begginings]</td>\n",
       "      <td>[beginning, ginning, binning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>beliefs: belives</td>\n",
       "      <td>beliefs</td>\n",
       "      <td>[belives]</td>\n",
       "      <td>[belief, belier, briefs]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0      wrong_word  \\\n",
       "0                  Apennines: Apenines Appenines       apennines   \n",
       "2                           Athenians: Atheneans       athenians   \n",
       "3                          Bernoulli: Bernouilli       bernoulli   \n",
       "9                            Cambridge: Cambrige       cambridge   \n",
       "10                               Caracas: carcas         caracas   \n",
       "14                            Catiline: Cataline        catiline   \n",
       "17                       Connecticut: Conneticut     connecticut   \n",
       "18                              Cypriot: Cyprian         cypriot   \n",
       "19                                   Ellis: eles           ellis   \n",
       "22                          Europeans: Europians       europeans   \n",
       "26                      Franciscans: Fransiscans     franciscans   \n",
       "28                          Galatians: Galations       galatians   \n",
       "29                                Gandhi: Ghandi          gandhi   \n",
       "30                                Gauguin: gogin         gauguin   \n",
       "31                          Guatemala: Guatamala       guatemala   \n",
       "33                             Guinness: Guiness        guinness   \n",
       "34                           Israelis: Israelies        israelis   \n",
       "40                                  Libya: Lybia           libya   \n",
       "43                          Mara_Liasson: liason    mara_liasson   \n",
       "44   Massachusetts: Massachussets Massachussetts   massachusetts   \n",
       "50                 Muslim: Mohammedan Muhammadan          muslim   \n",
       "51                          Muslims: Mohammedans         muslims   \n",
       "52                            Nazareth: Nazereth        nazareth   \n",
       "53                         New_Yorker: Newyorker      new_yorker   \n",
       "55                          Nuremberg: Nuremburg       nuremberg   \n",
       "61                               Puccini: Pucini         puccini   \n",
       "62                     Rockefeller: Rockerfeller     rockefeller   \n",
       "65                          Saturdays: Saterdays       saturdays   \n",
       "70                             Valletta: Valetta        valletta   \n",
       "73                            Zionists: Sionists        zionists   \n",
       "..                                           ...             ...   \n",
       "206                         anomalies: anomolies       anomalies   \n",
       "214                      apartments: appartments      apartments   \n",
       "216                        apologies: appologies       apologies   \n",
       "222                     appearances: appearences     appearances   \n",
       "225                        approaches: approachs      approaches   \n",
       "232               archaeologists: archeaologists  archaeologists   \n",
       "234                  archeologist: archeaologist    archeologist   \n",
       "235                archeologists: archeaologists   archeologists   \n",
       "236           archeology: archaoelogy archaology      archeology   \n",
       "238                        archetypes: archtypes      archetypes   \n",
       "240                       architects: archetects      architects   \n",
       "245                            archived: achived        archived   \n",
       "248                            arrested: erested        arrested   \n",
       "255                              aspects: spects         aspects   \n",
       "258                    assassinated: assasinated    assassinated   \n",
       "259                    assassinates: assasinates    assassinates   \n",
       "261                assassinations: assasinations  assassinations   \n",
       "262                          assassins: assasins       assassins   \n",
       "270                          attained: attaindre        attained   \n",
       "272                          attempted: attemted       attempted   \n",
       "273                        attempting: attemting      attempting   \n",
       "274                            attempts: attemts        attempts   \n",
       "277                       attendants: attendents      attendants   \n",
       "280                        attributes: atributes      attributes   \n",
       "287                          averaged: averageed        averaged   \n",
       "293                          bandwidth: bandwith       bandwidth   \n",
       "298                              became: becamae          became   \n",
       "305                         beginners: begginers       beginners   \n",
       "307                       beginnings: begginings      beginnings   \n",
       "311                             beliefs: belives         beliefs   \n",
       "\n",
       "                              target  \\\n",
       "0              [apenines, appenines]   \n",
       "2                        [atheneans]   \n",
       "3                       [bernouilli]   \n",
       "9                         [cambrige]   \n",
       "10                          [carcas]   \n",
       "14                        [cataline]   \n",
       "17                      [conneticut]   \n",
       "18                         [cyprian]   \n",
       "19                            [eles]   \n",
       "22                       [europians]   \n",
       "26                     [fransiscans]   \n",
       "28                       [galations]   \n",
       "29                          [ghandi]   \n",
       "30                           [gogin]   \n",
       "31                       [guatamala]   \n",
       "33                         [guiness]   \n",
       "34                       [israelies]   \n",
       "40                           [lybia]   \n",
       "43                          [liason]   \n",
       "44   [massachussets, massachussetts]   \n",
       "50          [mohammedan, muhammadan]   \n",
       "51                     [mohammedans]   \n",
       "52                        [nazereth]   \n",
       "53                       [newyorker]   \n",
       "55                       [nuremburg]   \n",
       "61                          [pucini]   \n",
       "62                    [rockerfeller]   \n",
       "65                       [saterdays]   \n",
       "70                         [valetta]   \n",
       "73                        [sionists]   \n",
       "..                               ...   \n",
       "206                      [anomolies]   \n",
       "214                    [appartments]   \n",
       "216                     [appologies]   \n",
       "222                    [appearences]   \n",
       "225                      [approachs]   \n",
       "232                 [archeaologists]   \n",
       "234                  [archeaologist]   \n",
       "235                 [archeaologists]   \n",
       "236        [archaoelogy, archaology]   \n",
       "238                      [archtypes]   \n",
       "240                     [archetects]   \n",
       "245                        [achived]   \n",
       "248                        [erested]   \n",
       "255                         [spects]   \n",
       "258                    [assasinated]   \n",
       "259                    [assasinates]   \n",
       "261                  [assasinations]   \n",
       "262                       [assasins]   \n",
       "270                      [attaindre]   \n",
       "272                       [attemted]   \n",
       "273                      [attemting]   \n",
       "274                        [attemts]   \n",
       "277                     [attendents]   \n",
       "280                      [atributes]   \n",
       "287                      [averageed]   \n",
       "293                       [bandwith]   \n",
       "298                        [becamae]   \n",
       "305                      [begginers]   \n",
       "307                     [begginings]   \n",
       "311                        [belives]   \n",
       "\n",
       "                                             y_hat  \n",
       "0                  [apennine, pentine, appendices]  \n",
       "2                  [athenian, athenianly, atheris]  \n",
       "3                 [bernoullian, beroll, seriously]  \n",
       "9                   [abridge, cartridge, labridae]  \n",
       "10                      [carajas, caracal, carica]  \n",
       "14                 [capeline, cathinine, catalina]  \n",
       "17          [connectant, connectivity, connective]  \n",
       "18                   [cypriote, cyprina, capriote]  \n",
       "19                          [elvis, bellis, allie]  \n",
       "22             [european, europeanly, europeanism]  \n",
       "26          [franciscan, francisca, franciscanism]  \n",
       "28                  [galatian, galaxian, palatian]  \n",
       "29                         [sandhi, gondi, gander]  \n",
       "30                       [gaduin, gaulin, gauging]  \n",
       "31                  [guatemalan, grateman, guemal]  \n",
       "33                  [guianese, vainness, twinness]  \n",
       "34                    [israeli, israel, ismaelism]  \n",
       "40                            [libra, libyan, iba]  \n",
       "43          [cabalassou, baralipton, moralization]  \n",
       "44             [massageuse, massacrer, massecuite]  \n",
       "50                         [muslin, musci, mulism]  \n",
       "51                      [muslin, muselike, tussis]  \n",
       "52                   [nazarite, lazaret, nazarene]  \n",
       "53                   [reworked, worker, newmarket]  \n",
       "55                      [number, november, curber]  \n",
       "61                    [puccinia, succinic, uncini]  \n",
       "62             [rocketeer, coreveller, backfiller]  \n",
       "65                 [saturday, saturnal, saturnale]  \n",
       "70                   [pallette, vallota, varletto]  \n",
       "73                   [zionist, zionistic, zionism]  \n",
       "..                                             ...  \n",
       "206              [animalier, anomalist, anomalous]  \n",
       "214            [apartment, apartmental, awardment]  \n",
       "216               [apologia, apologist, apologize]  \n",
       "222        [appearanced, appearance, coappearance]  \n",
       "225           [approacher, approachless, approach]  \n",
       "232  [archaeologist, archaeological, archaeologic]  \n",
       "234      [archaeologist, areologist, araneologist]  \n",
       "235   [archaeologist, araneologist, arachnologist]  \n",
       "236            [archaeology, archelogy, archology]  \n",
       "238            [archetype, archetypic, archetypal]  \n",
       "240        [architect, architecture, architeuthis]  \n",
       "245                    [archive, archival, archie]  \n",
       "248                  [arrestee, arrester, arrased]  \n",
       "255                        [aspect, specus, specs]  \n",
       "258    [assassinate, assassinator, unassassinated]  \n",
       "259    [assassinate, assassinator, assassinatress]  \n",
       "261  [assassination, assassinatress, assassinator]  \n",
       "262             [assassin, assassinist, assession]  \n",
       "270                 [attainer, trained, attainder]  \n",
       "272               [attempter, untempted, adempted]  \n",
       "273           [tempting, unattempting, untempting]  \n",
       "274                 [attempt, attempter, attemper]  \n",
       "277            [attendant, attendancy, attendance]  \n",
       "280            [attribute, attributer, attributal]  \n",
       "287                   [averager, average, avenage]  \n",
       "293                 [bindwith, bandaite, banditti]  \n",
       "298                       [befame, become, bename]  \n",
       "305                  [beginner, beginger, ginners]  \n",
       "307                  [beginning, ginning, binning]  \n",
       "311                       [belief, belier, briefs]  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.index = list(range(0,100))\n",
    "def accuracy():\n",
    "    True_word = 0\n",
    "    i = -1\n",
    "    for target in test_set['target']:\n",
    "        i = i + 1\n",
    "        for t in target:\n",
    "            if (t in test_set['y_hat'][i]):\n",
    "                True_word = True_word + 1\n",
    "                break\n",
    "    return True_word\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she will be there tommrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ('she', []),\n",
       " 1: ('will', []),\n",
       " 2: ('be', []),\n",
       " 3: ('there', []),\n",
       " 4: ('tommrow', ['tommyrot', 'tomorrow', 'throw', 'somehow', 'toro'])}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gui_condiate(\"she will be there tommrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the girls are comming to the meeting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ('the', []),\n",
       " 1: ('girls', []),\n",
       " 2: ('are', []),\n",
       " 3: ('comming', ['coaming', 'combing', 'coming', 'tomming', 'command']),\n",
       " 4: ('to', []),\n",
       " 5: ('the', []),\n",
       " 6: ('meeting', [])}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gui_condiate(\"the girls are comming to the meeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there was sing of neglect showing that no one was\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ('there', []),\n",
       " 1: ('was', []),\n",
       " 2: ('sing', ['going', 'kind', 'in', 'strong', 'such']),\n",
       " 3: ('of', []),\n",
       " 4: ('neglect', []),\n",
       " 5: ('showing', []),\n",
       " 6: ('that', []),\n",
       " 7: ('no', []),\n",
       " 8: ('one', []),\n",
       " 9: ('was', [])}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gui_condiate(\"there was sing of neglect showing that no one was\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i decided to climbed to the top of the hill to get better view\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ('i', []),\n",
       " 1: ('decided', []),\n",
       " 2: ('to', []),\n",
       " 3: ('climbed', ['come', 'leave', 'let', 'give', 'find']),\n",
       " 4: ('to', []),\n",
       " 5: ('the', []),\n",
       " 6: ('top', []),\n",
       " 7: ('of', []),\n",
       " 8: ('the', []),\n",
       " 9: ('hill', []),\n",
       " 10: ('to', []),\n",
       " 11: ('get', []),\n",
       " 12: ('better', []),\n",
       " 13: ('view', [])}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gui_condiate(\"i decided to climbed to the top of the hill to get better view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i saw the blind man crossed the busy road without any\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: ('i', []),\n",
       " 1: ('saw', []),\n",
       " 2: ('the', []),\n",
       " 3: ('blind', ['blood', 'plane', 'old', 'white', 'sun']),\n",
       " 4: ('man', []),\n",
       " 5: ('crossed', []),\n",
       " 6: ('the', []),\n",
       " 7: ('busy', []),\n",
       " 8: ('road', []),\n",
       " 9: ('without', []),\n",
       " 10: ('any', [])}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gui_condiate(\"i saw the blind man crossed the busy road without any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
